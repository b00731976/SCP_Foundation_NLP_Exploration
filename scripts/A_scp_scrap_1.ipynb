{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "cookies = {\"CONSENT\": \"YES+cb.20211025-07-p0.en+FX+410\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Going through the first gen of SCPs ####\n",
    "scp_number_list=[]\n",
    "scp_text_list=[]\n",
    "scp_rating_list=[]\n",
    "scp_discussion_list=[]\n",
    "\n",
    "for i in tqdm(range(2,2701)): # We limit the scrap to 2700 SCPs because of recent website changes affecting recent SCPs\n",
    "    # condition to put the accurate scp number in the link, we use the scp_number_prev and next to clean the footnote\n",
    "    if i>=2 and i<10:\n",
    "        scp_number = \"00\"+str(i)\n",
    "        scp_number_prev = \"00\"+str(i-1)\n",
    "        scp_number_next = \"00\"+str(i+1)\n",
    "        url = (\"https://scp-wiki.wikidot.com/scp-\"+scp_number)\n",
    "    elif i>=10 and i<100:\n",
    "        scp_number = \"0\"+str(i)\n",
    "        scp_number_prev = \"0\"+str(i-1)\n",
    "        scp_number_next = \"0\"+str(i+1)\n",
    "        url = (\"https://scp-wiki.wikidot.com/scp-\"+scp_number)\n",
    "    else:\n",
    "        scp_number = str(i)\n",
    "        scp_number_prev = str(i-1)\n",
    "        scp_number_next = str(i+1)\n",
    "        url = (\"https://scp-wiki.wikidot.com/scp-\"+scp_number)\n",
    "    # initializing our soup config\n",
    "    page = requests.get(url, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')    \n",
    "   \n",
    "    ##### Getting the text and the SCP number #####\n",
    "    div = soup.find(\"div\", {\"id\": \"page-content\"})\n",
    "    tag_types = [\"p\", \"ul\", \"li\"]\n",
    "    my_text=[]\n",
    "    # condition making sure we don't pick the stuff \n",
    "    if soup.find(\"div\", {\"class\": \"licensebox\"}): #returns none, some pages have a license part, some not\n",
    "        for item in range(len(div.find_all(tag_types))-6): # if license box, we  remove everything\n",
    "            my_text.append(div.find_all(tag_types)[item].get_text().strip())\n",
    "    else:\n",
    "        for item in range(len(div.find_all(tag_types))-2): # if not we remove just the necessary\n",
    "            my_text.append(div.find_all(tag_types)[item].get_text().strip())\n",
    "    # making sure we the \"item #: SCP-xxx\" is the start of the text if possible        \n",
    "    try:\n",
    "        start_index = my_text.index(\"Item #: SCP-\"+scp_number)\n",
    "        my_text = my_text[start_index:]\n",
    "    except:\n",
    "        pass\n",
    "    # making sure we don't pick the footnote navigation bar at the end\n",
    "    footnote = \"« SCP-\"+scp_number_prev+\" | SCP-\"+scp_number+\" | SCP-\"+scp_number_next+\" »\"\n",
    "    try:\n",
    "        footnote_index = my_text.index(footnote)\n",
    "        my_text = my_text[:footnote_index]\n",
    "    except:\n",
    "        pass\n",
    "    #####\n",
    "    \n",
    "    ##### Getting the rating and the discussion #####\n",
    "    div = soup.find(\"div\", {\"id\": \"page-options-bottom\"})\n",
    "    # Getting the rating\n",
    "    rating = div.find('a', id='pagerate-button').text\n",
    "    rating = rating.split('(', 1)[1].split(')')[0]\n",
    "    # Getting the discussion\n",
    "    discussion = (div.find('a', id='discuss-button')).text\n",
    "    discussion = discussion.split('(', 1)[1].split(')')[0]\n",
    "    #####\n",
    "    \n",
    "    # storing the results\n",
    "    scp_number_list.append(scp_number)\n",
    "    scp_text_list.append(my_text)\n",
    "    scp_rating_list.append(rating)\n",
    "    scp_discussion_list.append(discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_df = pd.DataFrame(columns = ['SCP Number', 'SCP Text', 'Ratings', 'Discussions'])\n",
    "scp_df.iloc[:,0] = scp_number_list\n",
    "scp_df.iloc[:,1] = scp_text_list\n",
    "scp_df.iloc[:,2] = scp_rating_list\n",
    "scp_df.iloc[:,3] = scp_discussion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_df[\"Ratings\"] = scp_df[\"Ratings\"].astype('int64')\n",
    "scp_df[\"Discussions\"] = scp_df[\"Discussions\"].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_df.to_csv('scp_20112021_export_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final table structure:\n",
    "\n",
    "# 1/ series\n",
    "# 2/ scp number\n",
    "# 3/ text\n",
    "# (optional) 3.5/ media if any \n",
    "# 4/ ratings\n",
    "# 5/ nbr discussions\n",
    "# 6/ tags\n",
    "# 7/ nbr page revisions\n",
    "# 8/ date last edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Questions to answer:\n",
    "\n",
    "## Sentiment through the SCPs\n",
    "## Most active years\n",
    "## sizes (just get the cm)\n",
    "## the people/orga in the SCP\n",
    "## the people/orga in the SCP and how they evolve through the SCP numbers\n",
    "## How these people/orga relate to each other -> Trying to make a lore out of everything\n",
    "## Is there a pattern to redactions ?\n",
    "## Is there a correlation with the ratings and: the theme of the SCP, the ratings, tags, sentiments and the object class ?\n",
    "## Keter vs Euclid vs Safe: What are their main textual patterns ?\n",
    "## Generate novel text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What to improve:\n",
    "    # Better scraping for earlier and for advanced series \n",
    "    # level 1,2,3,4 is not detected well: Making 'groups'\n",
    "    # we remove some words that need to stick together ... Or we seperate in token words that need to stick together otherwise they don't make sense \n",
    "    # Make functions instead\n",
    "    # Using SciBERT "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
